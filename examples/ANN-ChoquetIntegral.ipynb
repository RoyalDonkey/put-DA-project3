{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearGreaterThanZero(nn.Linear):\n",
    "    def __init__(self, in_features, bias=False, min_w=0.0000001):\n",
    "        super().__init__(in_features, 1, bias)\n",
    "        self.is_bias = bias\n",
    "        self.min_w = min_w\n",
    "        if bias:\n",
    "            nn.init.uniform_(self.bias, self.min_w, 1.0)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.uniform_(self.weight, 0.1, 1.0)\n",
    "\n",
    "    def w(self):\n",
    "        with torch.no_grad():\n",
    "            self.weight.data[self.weight.data < 0] = self.min_w\n",
    "        return self.weight\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.w(), self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearInteraction(nn.Linear):\n",
    "    def __init__(self, in_features, criterion_layer):\n",
    "        super().__init__(((in_features - 1) * in_features) // 2, 1, False)\n",
    "        self.in_features = in_features\n",
    "        self.criterion_layer = criterion_layer\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.weight, 0.0, 0.1)\n",
    "\n",
    "    def w(self):\n",
    "        with torch.no_grad():\n",
    "            w_i = 0\n",
    "            w = self.criterion_layer.w()\n",
    "            for i in range(self.in_features):\n",
    "                for j in range(i + 1, self.in_features):\n",
    "                    self.weight.data[:, w_i] = torch.max(\n",
    "                        self.weight.data[:, w_i], -w[:, i]\n",
    "                    )\n",
    "                    self.weight.data[:, w_i] = torch.max(\n",
    "                        self.weight.data[:, w_i], -w[:, j]\n",
    "                    )\n",
    "                    w_i += 1\n",
    "        return self.weight\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.w(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdLayer(nn.Module):\n",
    "    def __init__(self, threshold=None, requires_grad=True):\n",
    "        super().__init__()\n",
    "        if threshold is None:\n",
    "            self.threshold = nn.Parameter(\n",
    "                torch.FloatTensor(1).uniform_(0.1, 0.5), requires_grad=requires_grad\n",
    "            )\n",
    "        else:\n",
    "            self.threshold = nn.Parameter(\n",
    "                torch.FloatTensor([threshold]), requires_grad=requires_grad\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x - self.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChoquetConstrained(nn.Module):\n",
    "    def __init__(self, criteria_nr, **kwargs):\n",
    "        super().__init__()\n",
    "        self.criteria_nr = criteria_nr\n",
    "        self.criteria_layer = LinearGreaterThanZero(criteria_nr)\n",
    "        self.interaction_layer = LinearInteraction(criteria_nr, self.criteria_layer)\n",
    "        self.thresholdLayer = ThresholdLayer()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x[:, 0, :]\n",
    "        x_wi = self.criteria_layer(x[:, : self.criteria_nr])\n",
    "        x_wij = self.interaction_layer(x[:, self.criteria_nr :])\n",
    "        weight_sum = self.criteria_layer.w().sum() + self.interaction_layer.w().sum()\n",
    "        score = (x_wi + x_wij) / (weight_sum)\n",
    "        return self.thresholdLayer(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobious_transform(row):\n",
    "    return list(row) + [\n",
    "        min(row[i], row[j]) for i in range(len(row)) for j in range(i + 1, len(row))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/lectures-evaluation.csv\"\n",
    "data = pd.read_csv(path, header=None)\n",
    "target_map = {0: 0, 1: 0, 2: 0, 3: 1, 4: 1}\n",
    "criteria_nr = 4\n",
    "\n",
    "data_input = data.iloc[:, :criteria_nr].apply(\n",
    "    lambda x: mobious_transform(x), axis=1, result_type=\"expand\"\n",
    ")\n",
    "data_target = data[criteria_nr].apply(lambda x: target_map[x])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_input.values, data_target.values, test_size=0.2, random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = CreateDataLoader(X_train, y_train)\n",
    "test_dataloader = CreateDataLoader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"choquet.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChoquetConstrained(criteria_nr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:02<00:00, 70.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train:\t81.12%\n",
      "AUC train: \t82.50%\n",
      "\n",
      "Accuracy test:\t82.63%\n",
      "AUC test: \t84.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc, acc_test, auc, auc_test = Train(model, train_dataloader, test_dataloader, PATH)\n",
    "\n",
    "print(\"Accuracy train:\\t%.2f%%\" % (acc * 100.0))\n",
    "print(\"AUC train: \\t%.2f%%\" % (acc_test * 100.0))\n",
    "print()\n",
    "print(\"Accuracy test:\\t%.2f%%\" % (auc * 100.0))\n",
    "print(\"AUC test: \\t%.2f%%\" % (auc_test * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.criteria_layer.w().detach().numpy()[0]\n",
    "interaction_weights = model.interaction_layer.w().detach().numpy()[0]\n",
    "s = weights.sum() + interaction_weights.sum()\n",
    "weights = weights / s\n",
    "interaction_weights = interaction_weights / s\n",
    "\n",
    "interactions = np.zeros((criteria_nr, criteria_nr))\n",
    "weight_id = 0\n",
    "for i in range(criteria_nr):\n",
    "    for j in range(i + 1, criteria_nr):\n",
    "        interactions[i, j] = interactions[j, i] = interaction_weights[weight_id]\n",
    "        weight_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criteria weights:\n",
      "[0.20457476 0.22159435 0.2676533  0.22424388]\n",
      "\n",
      "Criteria interactions:\n",
      "[[ 0.          0.00227491  0.02014429  0.08775456]\n",
      " [ 0.00227491  0.         -0.05234363  0.03769386]\n",
      " [ 0.02014429 -0.05234363  0.         -0.01359024]\n",
      " [ 0.08775456  0.03769386 -0.01359024  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Criteria weights:\")\n",
    "print(weights)\n",
    "print()\n",
    "print(\"Criteria interactions:\")\n",
    "print(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance of criterina (Shapley value):\n",
      "[0.25966165 0.21540692 0.24475849 0.28017297]\n"
     ]
    }
   ],
   "source": [
    "shapley = weights + interactions.sum(0) / 2\n",
    "print(\"Importance of criterina (Shapley value):\")\n",
    "print(shapley)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
